{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-05T02:08:07.196392Z",
     "start_time": "2024-11-05T02:08:00.230299Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "def make_var_stationary(beta, radius=0.97):\n",
    "    '''Rescale coefficients of VAR model to make stable.'''\n",
    "    p = beta.shape[0]\n",
    "    lag = beta.shape[1] // p\n",
    "    bottom = np.hstack((np.eye(p * (lag - 1)), np.zeros((p * (lag - 1), p))))\n",
    "    beta_tilde = np.vstack((beta, bottom))\n",
    "    eigvals = np.linalg.eigvals(beta_tilde)\n",
    "    max_eig = max(np.abs(eigvals))\n",
    "    nonstationary = max_eig > radius\n",
    "    if nonstationary:\n",
    "        return make_var_stationary(0.95 * beta, radius)\n",
    "    else:\n",
    "        return beta\n",
    "\n",
    "def simulate_var(p, T, lag, sparsity=0.2, beta_value=1.0, sd=0.1, seed=0):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Set up coefficients and Granger causality ground truth.\n",
    "    GC = np.eye(p, dtype=int)\n",
    "    beta = np.eye(p) * beta_value\n",
    "\n",
    "    num_nonzero = int(p * sparsity) - 1\n",
    "    for i in range(p):\n",
    "        choice = np.random.choice(p - 1, size=num_nonzero, replace=False)\n",
    "        choice[choice >= i] += 1\n",
    "        beta[i, choice] = beta_value\n",
    "        GC[i, choice] = 1\n",
    "\n",
    "    beta = np.hstack([beta for _ in range(lag)])\n",
    "    beta = make_var_stationary(beta)\n",
    "\n",
    "    # Generate data.\n",
    "    burn_in = 100\n",
    "    errors = np.random.normal(scale=sd, size=(p, T + burn_in))\n",
    "    X = np.zeros((p, T + burn_in))\n",
    "    X[:, :lag] = errors[:, :lag]\n",
    "    for t in range(lag, T + burn_in):\n",
    "        X[:, t] = np.dot(beta, X[:, (t-lag):t].flatten(order='F'))\n",
    "        X[:, t] += errors[:, t-1]\n",
    "\n",
    "    return X.T[burn_in:], beta, GC\n",
    "\n",
    "def lorenz(x, t, F):\n",
    "    '''Partial derivatives for Lorenz-96 ODE.'''\n",
    "    p = len(x)\n",
    "    dxdt = np.zeros(p)\n",
    "    for i in range(p):\n",
    "        dxdt[i] = (x[(i+1) % p] - x[(i-2) % p]) * x[(i-1) % p] - x[i] + F\n",
    "\n",
    "    return dxdt\n",
    "\n",
    "def simulate_lorenz_96(p, T, F=10.0, delta_t=0.1, sd=0.1, burn_in=1000, seed=0):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Use scipy to solve ODE.\n",
    "    x0 = np.random.normal(scale=0.01, size=p)\n",
    "    t = np.linspace(0, (T + burn_in) * delta_t, T + burn_in)\n",
    "    X = odeint(lorenz, x0, t, args=(F,))\n",
    "    X += np.random.normal(scale=sd, size=(T + burn_in, p))\n",
    "\n",
    "    # Set up Granger causality ground truth.\n",
    "    GC = np.zeros((p, p), dtype=int)\n",
    "    for i in range(p):\n",
    "        GC[i, i] = 1\n",
    "        GC[i, (i + 1) % p] = 1\n",
    "        GC[i, (i - 1) % p] = 1\n",
    "        GC[i, (i - 2) % p] = 1\n",
    "\n",
    "    return X[burn_in:], GC\n",
    "\n",
    "# Parameters for simulation\n",
    "T_values = [200, 500, 1000]\n",
    "seeds = [169, 381, 584, 594, 618, 671, 981]\n",
    "p = 5  # number of variables\n",
    "lag = 5  # VAR lag\n",
    "sparsity = 0.2\n",
    "beta_value = 1.0\n",
    "sd = 0.1\n",
    "F = 10.0\n",
    "delta_t = 0.1\n",
    "burn_in = 1000\n",
    "\n",
    "# Simulating VAR and Lorenz models and saving results\n",
    "for T in T_values:\n",
    "    for seed in seeds:\n",
    "        # Simulate VAR model\n",
    "        X_var, beta, GC_var = simulate_var(p, T, lag, sparsity=sparsity, beta_value=beta_value, sd=sd, seed=seed)\n",
    "        np.savez(f'results_var_T_{T}_seed_{seed}.npz', \n",
    "                 X_np=X_var, \n",
    "                 Gref=GC_var, \n",
    "                 n=p, \n",
    "                 T=T, \n",
    "                 sparsity=sparsity, \n",
    "                 var_lag=lag, \n",
    "                 sd=sd, \n",
    "                 beta_value=beta_value, \n",
    "                 seed=seed)\n",
    "\n",
    "        # Simulate Lorenz model\n",
    "        X_lorenz, GC_lorenz = simulate_lorenz_96(p, T, F=F, delta_t=delta_t, sd=sd, burn_in=burn_in, seed=seed)\n",
    "        np.savez(f'results_lorenz_T_{T}_seed_{seed}.npz', \n",
    "                 X_np=X_lorenz, \n",
    "                 Gref=GC_lorenz, \n",
    "                 n=p, \n",
    "                 T=T, \n",
    "                 F=F, \n",
    "                 delta_t=delta_t, \n",
    "                 sd=sd, \n",
    "                 burn_in=burn_in, \n",
    "                 seed=seed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
